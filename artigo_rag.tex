\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{times} 
\usepackage{geometry}
\usepackage{fancyhdr} 
\usepackage{setspace} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{indentfirst}

\geometry{a4paper, margin=1in}



\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.2pt} 
\fancyhead[L]{\small Proceedings of the 40\textsuperscript{th} Brazilian Symposium on Data Bases}
\fancyhead[R]{\small April 2025 – Santa Maria, RS, Brazil}

\begin{document}

\vspace{2cm}

\begin{center}
    {\Large\bfseries Evaluation of the Efficiency of \\
    Retrieval-Augmented Generation Systems\\
    for Solving Programming Problems \\[1em]}
    
    \normalsize
    Gabriel Machado Lunardi, Gabriel Souza Baggio\textsuperscript{1}\\[0.5em]
    
    \small
    \textsuperscript{1}Computer Science Department - Universidade Federal de Santa Maria - Santa Maria, RS, Brasil
\end{center}

\vspace{1cm}

\noindent
\textbf{Abstract.} \textit{
This study presents several tests on the use of Retrieval-Augmented Generation (RAG) in solving programming problems. It also contains a select programming questions database, comprising a diverse collection of challenges from a well-known competitive programming platform. The results demonstrate that incorporating relevant code examples and algorithmic explanations improves the quality and efficiency of solutions generated by large language models (LLMs), especially in problems that require specific knowledge or have harder logical approaches. The proposed methodology not only improves the accuracy of the solutions, but also provides more detailed and instructive explanations, suggesting significant potential for educational applications.
}

\vspace{1cm}

\section{Introduction}
Embora os modelos de linguagem de grande escala (LLMs) tenham demonstrado capacidades impressionantes na geração de código, eles frequentemente produzem soluções incorretas ou ineficientes para problemas algorítmicos complexos devido à ausência de conhecimento contextual específico e compreensão aprofundada de estruturas de dados.

\begin{thebibliography}{99}
    \bibitem{lewis2020rag} Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020.
    
    \bibitem{chen2021codex} Chen, M., et al. (2021). Evaluating Large Language Models Trained on Code. arXiv preprint arXiv:2107.03374.
    
    \bibitem{izacard2022atlas} Izacard, G., et al. (2022). Atlas: Few-shot Learning with Retrieval Augmented Language Models. arXiv preprint arXiv:2208.03299.
    
\end{thebibliography}

\end{document}